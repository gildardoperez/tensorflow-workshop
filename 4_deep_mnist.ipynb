{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to train a neural network with one hidden layer on MNIST. At the end is a short exercise to add a second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "def ResetSession():\n",
    "    tf.reset_default_graph()\n",
    "    global sess\n",
    "    if sess is not None: sess.close()\n",
    "    sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for a single hidden layer nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "loss is %f 2.34853\n",
      "loss is %f 0.177169\n",
      "loss is %f 0.273267\n",
      "loss is %f 0.241952\n",
      "loss is %f 0.0798445\n",
      "Accuracy is %f 0.9672\n"
     ]
    }
   ],
   "source": [
    "ResetSession()\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_PIXELS = 28*28\n",
    "TRAIN_STEPS = 1000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "HIDDEN1_UNITS = 128\n",
    "LEARNING_RATE = 0.5\n",
    "\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, NUM_PIXELS], name = \"pixels\")\n",
    "y_ = tf.placeholder(dtype = tf.float32, shape = [None, NUM_CLASSES], name = \"labels\")\n",
    "\n",
    "def weight_variable(inputs, outputs, name):\n",
    "    initial = tf.truncated_normal(shape = [inputs, outputs], stddev=1.0/ math.sqrt(float(inputs)))\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.0, shape = [shape])\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "weights1 = weight_variable(NUM_PIXELS, HIDDEN1_UNITS, \"weights1\")\n",
    "biases1 = bias_variable(HIDDEN1_UNITS, \"biases1\")\n",
    "hidden1 = tf.nn.relu(tf.matmul(x, weights1) + biases1, name=\"hidden1\")\n",
    "\n",
    "weights2 = weight_variable(HIDDEN1_UNITS, NUM_CLASSES, \"weights2\")\n",
    "biases2 = bias_variable(NUM_CLASSES, \"biases2\")\n",
    "\n",
    "y = tf.add(tf.matmul(hidden1, weights2), biases2)\n",
    "\n",
    "summary_writer = tf.train.SummaryWriter(\"summaries/single_hidden_layer\", graph=tf.get_default_graph())\n",
    "summary_writer.close()\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(TRAIN_STEPS):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "    _, loss = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if i%200 == 0:\n",
    "        print(\"loss is %f\", loss)\n",
    "        \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"Accuracy is %f\", sess.run(accuracy, feed_dict = {x:mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Add a second hidden layer to the above code, with 64 units. Experiment with the parameters (batch size, steps, learning rate, units per layer) to see if you can achieve higher accuracy than the single hidden layer model. Keep in mind there's randomness between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(train_steps, batch_size, units1, units2, learning_rate):\n",
    "    ResetSession()\n",
    "\n",
    "    mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "    NUM_CLASSES = 10\n",
    "    NUM_PIXELS = 28*28\n",
    "    TRAIN_STEPS = train_steps\n",
    "    BATCH_SIZE = batch_size\n",
    "\n",
    "    HIDDEN1_UNITS = units1\n",
    "    HIDDEN2_UNITS = units2\n",
    "    LEARNING_RATE = learning_rate\n",
    "\n",
    "    x = tf.placeholder(dtype = tf.float32, shape = [None, NUM_PIXELS], name = \"pixels\")\n",
    "    y_ = tf.placeholder(dtype = tf.float32, shape = [None, NUM_CLASSES], name = \"labels\")\n",
    "\n",
    "    def weight_variable(inputs, outputs, name):\n",
    "        initial = tf.truncated_normal(shape = [inputs, outputs], stddev=1.0/ math.sqrt(float(inputs)))\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    def bias_variable(shape, name):\n",
    "        initial = tf.constant(0.0, shape = [shape])\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    weights1 = weight_variable(NUM_PIXELS, HIDDEN1_UNITS, \"weights1\")\n",
    "    biases1 = bias_variable(HIDDEN1_UNITS, \"biases1\")\n",
    "    hidden1 = tf.nn.relu(tf.matmul(x, weights1) + biases1, name=\"hidden1\")\n",
    "\n",
    "    weights2 = weight_variable(HIDDEN1_UNITS, HIDDEN2_UNITS, \"weights2\")\n",
    "    biases2 = bias_variable(HIDDEN2_UNITS, \"biases2\")\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights2) + biases2, name = \"hidden2\")\n",
    "\n",
    "    weights3 = weight_variable(HIDDEN2_UNITS, NUM_CLASSES, \"weights3\")\n",
    "    biases3 = bias_variable(NUM_CLASSES, \"biases3\")\n",
    "\n",
    "    y = tf.add(tf.matmul(hidden2, weights3), biases3)\n",
    "\n",
    "    summary_writer = tf.train.SummaryWriter(\"summaries/single_hidden_layer\", graph=tf.get_default_graph())\n",
    "    summary_writer.close()\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(TRAIN_STEPS):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "        _, loss = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        if i%200 == 0:\n",
    "            print(\"At step %d, loss is %f\" % (i, loss))\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    print(\"Accuracy is %f\", sess.run(accuracy, feed_dict = {x:mnist.test.images, y_: mnist.test.labels}))\n",
    "    return sess.run(accuracy, feed_dict = {x:mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GsRunner():\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_steps = [1000,2000,5000,],\n",
    "        batch_size = [100, 250, 500, 1000,],\n",
    "        units1 = [4, 8, 16, 32, 64, 128, 256,],\n",
    "        units2 = [4, 8, 16, 32, 64, 128, 256,],\n",
    "        learning_rate = [0.3, 0.4, 0.5, 0.6]\n",
    "                ):\n",
    "        self.best = {\n",
    "            \"val\": 0, \n",
    "            \"train_steps\": None, \n",
    "            \"batch_size\": None, \n",
    "            \"units1\": None, \n",
    "            \"units2\": None, \n",
    "            \"learning_rate\": None\n",
    "        }\n",
    "        self.HP = {\n",
    "            \"train_steps\": train_steps,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"units1\": units1,\n",
    "            \"units2\": units2,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \n",
    "        }\n",
    "\n",
    "    def update(self, val, **kwargs):\n",
    "        if val>self.best[\"val\"]:\n",
    "            self.best[\"val\"] = val\n",
    "            for k in kwargs.keys():\n",
    "                self.best[k] = kwargs[k]\n",
    "            return\n",
    "\n",
    "    def runner(self):\n",
    "        for train_steps in self.HP[\"train_steps\"]:\n",
    "            for batch_size in self.HP[\"batch_size\"]:\n",
    "                for units1 in self.HP[\"units1\"]:\n",
    "                    for units2 in self.HP[\"units2\"]:\n",
    "                        for learning_rate in self.HP[\"learning_rate\"]:\n",
    "                            kwargs={\n",
    "                                    \"train_steps\": train_steps,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"units1\": units1,\n",
    "                                    \"units2\": units2,\n",
    "                                    \"learning_rate\": learning_rate,\n",
    "                                    \n",
    "                                }\n",
    "                            self.update(run(train_steps, batch_size, units1, units2, learning_rate),\n",
    "                                       **kwargs)\n",
    "        return self.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.313547\n",
      "At step 200, loss is 1.130637\n",
      "At step 400, loss is 1.025067\n",
      "At step 600, loss is 1.173610\n",
      "At step 800, loss is 2.207865\n",
      "Accuracy is %f 0.2126\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.313341\n",
      "At step 200, loss is 2.320842\n",
      "At step 400, loss is 2.297128\n",
      "At step 600, loss is 1.738284\n",
      "At step 800, loss is 1.741569\n",
      "Accuracy is %f 0.2839\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.300416\n",
      "At step 200, loss is 0.956067\n",
      "At step 400, loss is 1.146738\n",
      "At step 600, loss is 1.190433\n",
      "At step 800, loss is 1.106809\n",
      "Accuracy is %f 0.5233\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.295085\n",
      "At step 200, loss is 1.991412\n",
      "At step 400, loss is 1.454087\n",
      "At step 600, loss is 1.420072\n",
      "At step 800, loss is 1.462687\n",
      "Accuracy is %f 0.3545\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.302400\n",
      "At step 200, loss is 0.910777\n",
      "At step 400, loss is 0.846440\n",
      "At step 600, loss is 0.911110\n",
      "At step 800, loss is 0.885655\n",
      "Accuracy is %f 0.6651\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.284053\n",
      "At step 200, loss is 0.663974\n",
      "At step 400, loss is 0.772706\n",
      "At step 600, loss is 0.625394\n",
      "At step 800, loss is 1.007349\n",
      "Accuracy is %f 0.7822\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.313374\n",
      "At step 200, loss is 0.702876\n",
      "At step 400, loss is 0.609975\n",
      "At step 600, loss is 0.641087\n",
      "At step 800, loss is 0.852806\n",
      "Accuracy is %f 0.8318\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.299902\n",
      "At step 200, loss is 1.085161\n",
      "At step 400, loss is 0.813309\n",
      "At step 600, loss is 0.841710\n",
      "At step 800, loss is 1.060872\n",
      "Accuracy is %f 0.7758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 50,\n",
       " 'learning_rate': 0.5,\n",
       " 'train_steps': 1000,\n",
       " 'units1': 8,\n",
       " 'units2': 8,\n",
       " 'val': 0.83179998}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = GsRunner(train_steps=[1000], batch_size=[50], units1=[4,8], units2=[4,8], learning_rate=[0.5,0.8])\n",
    "x.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.317746\n",
      "At step 200, loss is 2.298059\n",
      "At step 400, loss is 2.299014\n",
      "At step 600, loss is 2.310136\n",
      "At step 800, loss is 2.299799\n",
      "Accuracy is %f 0.1135\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.317506\n",
      "At step 200, loss is 1.921731\n",
      "At step 400, loss is 2.709044\n",
      "At step 600, loss is 1.386878\n",
      "At step 800, loss is 1.441304\n",
      "Accuracy is %f 0.4215\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "At step 0, loss is 2.312166\n",
      "At step 200, loss is 2.086142\n",
      "At step 400, loss is 1.855787\n",
      "At step 600, loss is 1.844401\n",
      "At step 800, loss is 2.311781\n",
      "Accuracy is %f 0.1028\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting"
     ]
    }
   ],
   "source": [
    "y = GsRunner()\n",
    "thebest = y.runner()\n",
    "print(\"Best accuracy found is \", thebest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
